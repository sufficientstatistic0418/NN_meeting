{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 前置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run\"MLP_lib.ipynb\"\n",
    "import librosa, os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.資料處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path0 = \"/Users/chtsou/Desktop/統研/論文相關/database/0922meeting用3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ -4.82142000e+01,  -6.87033400e+00,   4.56417500e+01, ...,\n",
      "         -7.94552900e-01,  -1.04740800e+00,   3.74651000e+00],\n",
      "       [ -2.95971800e+01,   1.09335200e+01,   4.33798300e+01, ...,\n",
      "          2.70893100e+00,   2.90836500e+00,   8.69913000e-01],\n",
      "       [ -5.52936300e+01,  -3.83949800e+00,   4.83102200e+01, ...,\n",
      "         -7.92458100e-01,  -9.50152400e-01,   4.61278000e-01],\n",
      "       ..., \n",
      "       [ -3.80405000e+01,   2.41489700e+01,   5.35279800e+00, ...,\n",
      "          2.14572200e-01,  -4.45081300e-01,  -2.28587600e+00],\n",
      "       [ -2.75461700e+01,   1.10000200e+01,  -3.40320000e+00, ...,\n",
      "          1.09544300e+00,   1.31733100e+00,   2.45061100e+00],\n",
      "       [ -2.62666800e+01,   2.56865200e+01,   3.01310200e+00, ...,\n",
      "          7.99602700e-01,  -5.46483700e-02,   2.98498700e+00]]), array([[ 0.,  1.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.,  0.]]))\n",
      "  \n",
      "Dims of x_input: (466, 975)\n",
      "Dims of y_input: (466, 5)\n"
     ]
    }
   ],
   "source": [
    "data = connect_data_folder(path0, [\"一\", \"丁\", \"七\", \"刀\", \"八\"])\n",
    "print(data)\n",
    "print(\"  \")\n",
    "print(\"Dims of x_input:\", data[0].shape)\n",
    "print(\"Dims of y_input:\", data[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Splits train & test\n",
    "### 訓練464筆，測試52筆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train data: 419\n",
      "Size of train data: 47\n"
     ]
    }
   ],
   "source": [
    "nrow = len(data[0][:, 1])\n",
    "test_x, test_y = data[0][range(3, nrow, 10)], data[1][range(3, nrow, 10)]\n",
    "train_x, train_y = np.delete(data[0], range(3, nrow, 10), 0), np.delete(data[1], range(3, nrow, 10), 0)\n",
    "\n",
    "train_data = train_x, train_y\n",
    "test_data = test_x, test_y\n",
    "\n",
    "print(\"Size of train data:\", train_x.shape[0])\n",
    "print(\"Size of train data:\", test_x.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Spliting train&test data by frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dims of ith sp_frame_x: (25, 419, 39)\n",
      "Dims of ith sp_frame_y: (419, 5)\n",
      "-------------------------------------\n",
      "Dims of ith sp_frame_x: (25, 47, 39)\n",
      "Dims of ith sp_frame_y: (47, 5)\n"
     ]
    }
   ],
   "source": [
    "train_by_frame = frame_split22(train_data, 25)\n",
    "print(\"Dims of ith sp_frame_x:\", train_by_frame[0].shape)\n",
    "\n",
    "print(\"Dims of ith sp_frame_y:\", train_by_frame[1].shape)\n",
    "\n",
    "print(\"-------------------------------------\")\n",
    "test_by_frame = frame_split22(test_data, 25)\n",
    "print(\"Dims of ith sp_frame_x:\", test_by_frame[0].shape)\n",
    "\n",
    "print(\"Dims of ith sp_frame_y:\", test_by_frame[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Scaling data by train_mean & train_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale_tup = get_mean_and_sd(train_data[0])\n",
    "train_x_std = scale_by_train(train_by_frame[0], scale_tup[0], scale_tup[1])\n",
    "test_x_std = scale_by_train(test_by_frame[0], scale_tup[0], scale_tup[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "#  \n",
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 搭建框架"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 設定各層神經元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_in = 39\n",
    "n_h = 100\n",
    "n_out = 5\n",
    "n_fr = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 定義layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # add one more layer and return the output of this layer\n",
    "    with tf.name_scope('layer'):\n",
    "        with tf.name_scope('weights'):\n",
    "#             Weights = tf.Variable(tf.random_normal([in_size, out_size]), name='W')\n",
    "            Weights = tf.Variable(tf.random_normal([in_size, out_size], mean=0., stddev=0.3))\n",
    "        with tf.name_scope('biases'):\n",
    "            biases = tf.Variable(tf.zeros([1, out_size]) + 0.1, name='b') # \n",
    "#             biases = tf.Variable(tf.zeros([1, out_size]) + 0.03)\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "        if activation_function is None:\n",
    "            outputs = Wx_plus_b\n",
    "        else:\n",
    "            outputs = activation_function(Wx_plus_b)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_list = list(np.zeros(n_fr))\n",
    "prediction_list = list(np.zeros(n_fr))\n",
    "xs = tf.placeholder(tf.float32, [None, n_in])\n",
    "ys = tf.placeholder(tf.float32, [None, n_out])\n",
    "for i in range(n_fr):\n",
    "    hidden_list[i] = add_layer(xs, n_in, n_h, activation_function=tf.nn.tanh)\n",
    "    prediction_list[i] = add_layer(hidden_list[i], n_h, n_out, activation_function=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(v_xs, v_ys, prediction):\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs})  \n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre, 1), tf.argmax(v_ys, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys: v_ys})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "#   \n",
    "#   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output_pr_frame(v_xs, prediction):\n",
    "    y_pre = sess.run(prediction, feed_dict={xs: v_xs})  \n",
    "#     correct_prediction = tf.equal(tf.argmax(y_pre, 1), tf.argmax(v_ys, 1))\n",
    "#     y = sess.run(correct_prediction)\n",
    "    return y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_data: tuple of test data\n",
    "# i_fr: 分音框數\n",
    "# pr_array每列和為25\n",
    "def test_accuracy(test_x_by_frame, test_y, n_fr, prediction):\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    input_x = test_x_by_frame[0]\n",
    "    input_y = test_y\n",
    "    y_pre = output_pr_frame(input_x, prediction[0])\n",
    "    y_pre_shape = y_pre.shape        # 容器大小\n",
    "    pr_array = tf.zeros(y_pre_shape) # 容器\n",
    "    \n",
    "    for n_fr in range(n_fr):\n",
    "        input_x = test_x_by_frame[n_fr]\n",
    "#         sess.run(prediction, feed_dict={xs: v_xs})\n",
    "        pr_array += output_pr_frame(input_x, prediction[n_fr])\n",
    "        \n",
    "    correct_prediction = tf.equal(tf.argmax(pr_array, 1), tf.argmax(input_y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    result = sess.run(accuracy)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 訓練模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 開始逐個音框訓練模型，正確率夠大就提早停止"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---frame 1\n",
      "0.696897\n",
      "0.990453\n",
      "0.990453\n",
      "---frame 2\n",
      "0.763723\n",
      "0.995227\n",
      "0.995227\n",
      "---frame 3\n",
      "0.821002\n",
      "0.997613\n",
      "0.997613\n",
      "---frame 4\n",
      "0.830549\n",
      "0.988067\n",
      "0.995227\n",
      "0.995227\n",
      "---frame 5\n",
      "0.778043\n",
      "0.988067\n",
      "0.995227\n",
      "0.995227\n",
      "---frame 6\n",
      "0.825776\n",
      "0.995227\n",
      "0.995227\n",
      "---frame 7\n",
      "0.763723\n",
      "0.995227\n",
      "0.995227\n",
      "---frame 8\n",
      "0.75895\n",
      "0.990453\n",
      "0.990453\n",
      "---frame 9\n",
      "0.789976\n",
      "0.98568\n",
      "0.997613\n",
      "0.997613\n",
      "---frame 10\n",
      "0.804296\n",
      "0.990453\n",
      "0.990453\n",
      "---frame 11\n",
      "0.832936\n",
      "0.99284\n",
      "0.99284\n",
      "---frame 12\n",
      "0.809069\n",
      "0.988067\n",
      "0.995227\n",
      "0.995227\n",
      "---frame 13\n",
      "0.809069\n",
      "0.99284\n",
      "0.99284\n",
      "---frame 14\n",
      "0.828162\n",
      "0.988067\n",
      "0.997613\n",
      "0.997613\n",
      "---frame 15\n",
      "0.789976\n",
      "0.995227\n",
      "0.995227\n",
      "---frame 16\n",
      "0.813842\n",
      "0.99284\n",
      "0.99284\n",
      "---frame 17\n",
      "0.842482\n",
      "0.990453\n",
      "0.990453\n",
      "---frame 18\n",
      "0.785203\n",
      "0.988067\n",
      "0.997613\n",
      "0.997613\n",
      "---frame 19\n",
      "0.809069\n",
      "0.990453\n",
      "0.990453\n",
      "---frame 20\n",
      "0.799523\n",
      "0.990453\n",
      "0.990453\n",
      "---frame 21\n",
      "0.77327\n",
      "0.98568\n",
      "1.0\n",
      "1.0\n",
      "---frame 22\n",
      "0.768496\n",
      "0.988067\n",
      "1.0\n",
      "1.0\n",
      "---frame 23\n",
      "0.768496\n",
      "0.997613\n",
      "0.997613\n",
      "---frame 24\n",
      "0.761337\n",
      "0.995227\n",
      "0.995227\n",
      "---frame 25\n",
      "0.749403\n",
      "0.990453\n",
      "0.990453\n"
     ]
    }
   ],
   "source": [
    "batch_ys = train_y\n",
    "input_y = train_y\n",
    "for fr_index in range(25):\n",
    "    batch_xs = train_by_frame[0][fr_index, :, :]\n",
    "    input_x = train_by_frame[0][fr_index, :, :]\n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction_list[fr_index]), reduction_indices=[1]))\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "    \n",
    "    print(\"---frame\", fr_index + 1)\n",
    "    for j in range(1000):\n",
    "        sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})\n",
    "        if j % 100 == 0:\n",
    "            c = compute_accuracy(input_x, input_y, prediction_list[fr_index])\n",
    "            print(c)\n",
    "        if c > 0.99:\n",
    "            print(c)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.87234\n"
     ]
    }
   ],
   "source": [
    "print(test_accuracy(train_by_frame[0], train_by_frame[1], 25, prediction_list))\n",
    "print(test_accuracy(test_by_frame[0], test_by_frame[1], 25, prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 標準化訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---frame 1\n",
      "0.279236\n",
      "1.0\n",
      "1.0\n",
      "---frame 2\n",
      "0.231504\n",
      "1.0\n",
      "1.0\n",
      "---frame 3\n",
      "0.279236\n",
      "1.0\n",
      "1.0\n",
      "---frame 4\n",
      "0.236277\n",
      "1.0\n",
      "1.0\n",
      "---frame 5\n",
      "0.229117\n",
      "1.0\n",
      "1.0\n",
      "---frame 6\n",
      "0.252983\n",
      "1.0\n",
      "1.0\n",
      "---frame 7\n",
      "0.200477\n",
      "1.0\n",
      "1.0\n",
      "---frame 8\n",
      "0.264916\n",
      "1.0\n",
      "1.0\n",
      "---frame 9\n",
      "0.195704\n",
      "0.997613\n",
      "0.997613\n",
      "---frame 10\n",
      "0.229117\n",
      "1.0\n",
      "1.0\n",
      "---frame 11\n",
      "0.231504\n",
      "1.0\n",
      "1.0\n",
      "---frame 12\n",
      "0.171838\n",
      "1.0\n",
      "1.0\n",
      "---frame 13\n",
      "0.169451\n",
      "0.997613\n",
      "0.997613\n",
      "---frame 14\n",
      "0.167064\n",
      "0.997613\n",
      "0.997613\n",
      "---frame 15\n",
      "0.176611\n",
      "0.997613\n",
      "0.997613\n",
      "---frame 16\n",
      "0.295943\n",
      "1.0\n",
      "1.0\n",
      "---frame 17\n",
      "0.231504\n",
      "0.990453\n",
      "0.990453\n",
      "---frame 18\n",
      "0.22673\n",
      "0.99284\n",
      "0.99284\n",
      "---frame 19\n",
      "0.229117\n",
      "0.997613\n",
      "0.997613\n",
      "---frame 20\n",
      "0.264916\n",
      "0.995227\n",
      "0.995227\n",
      "---frame 21\n",
      "0.193317\n",
      "0.988067\n",
      "1.0\n",
      "1.0\n",
      "---frame 22\n",
      "0.23389\n",
      "0.995227\n",
      "0.995227\n",
      "---frame 23\n",
      "0.186158\n",
      "0.995227\n",
      "0.995227\n",
      "---frame 24\n",
      "0.23389\n",
      "0.995227\n",
      "0.995227\n",
      "---frame 25\n",
      "0.210024\n",
      "0.99284\n",
      "0.99284\n"
     ]
    }
   ],
   "source": [
    "batch_ys = train_y\n",
    "input_y = train_y\n",
    "for fr_index in range(25):\n",
    "    batch_xs = train_x_std[fr_index, :, :]\n",
    "    input_x = train_x_std[fr_index, :, :]\n",
    "    \n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction_list[fr_index]), reduction_indices=[1]))\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.05).minimize(cross_entropy)\n",
    "    \n",
    "    print(\"---frame\", fr_index + 1)\n",
    "    for j in range(3000):\n",
    "        sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})\n",
    "        if j % 1000 == 0:\n",
    "            c = compute_accuracy(input_x, input_y, prediction_list[fr_index])\n",
    "            print(c)\n",
    "        if c > 0.99:\n",
    "            print(c)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.914894\n"
     ]
    }
   ],
   "source": [
    "print(test_accuracy(train_x_std, train_by_frame[1], 25, prediction_list))\n",
    "print(test_accuracy(test_x_std, test_by_frame[1], 25, prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 隨機抽取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---frame 1\n",
      "1.0\n",
      "1.0\n",
      "---frame 2\n",
      "1.0\n",
      "1.0\n",
      "---frame 3\n",
      "1.0\n",
      "1.0\n",
      "---frame 4\n",
      "1.0\n",
      "1.0\n",
      "---frame 5\n",
      "1.0\n",
      "1.0\n",
      "---frame 6\n",
      "1.0\n",
      "1.0\n",
      "---frame 7\n",
      "1.0\n",
      "1.0\n",
      "---frame 8\n",
      "1.0\n",
      "1.0\n",
      "---frame 9\n",
      "0.997613\n",
      "0.997613\n",
      "---frame 10\n",
      "1.0\n",
      "1.0\n",
      "---frame 11\n",
      "1.0\n",
      "1.0\n",
      "---frame 12\n",
      "1.0\n",
      "1.0\n",
      "---frame 13\n",
      "1.0\n",
      "1.0\n",
      "---frame 14\n",
      "1.0\n",
      "1.0\n",
      "---frame 15\n",
      "1.0\n",
      "1.0\n",
      "---frame 16\n",
      "1.0\n",
      "1.0\n",
      "---frame 17\n",
      "1.0\n",
      "1.0\n",
      "---frame 18\n",
      "1.0\n",
      "1.0\n",
      "---frame 19\n",
      "1.0\n",
      "1.0\n",
      "---frame 20\n",
      "1.0\n",
      "1.0\n",
      "---frame 21\n",
      "1.0\n",
      "1.0\n",
      "---frame 22\n",
      "1.0\n",
      "1.0\n",
      "---frame 23\n",
      "1.0\n",
      "1.0\n",
      "---frame 24\n",
      "0.997613\n",
      "0.997613\n",
      "---frame 25\n",
      "0.995227\n",
      "0.995227\n"
     ]
    }
   ],
   "source": [
    "sample_size = train_y.shape[0]\n",
    "\n",
    "input_y = train_y\n",
    "batch_size = 30\n",
    "\n",
    "for fr_index in range(25):\n",
    "    input_x = train_x_std2[fr_index, :, :]\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction_list[fr_index]), reduction_indices=[1]))\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n",
    "    print(\"---frame\", fr_index + 1)\n",
    "    for j in range(3000): \n",
    "        bat_i = np.random.choice(range(sample_size), batch_size)\n",
    "    \n",
    "        batch_xs = train_x_std2[fr_index, bat_i, :]\n",
    "        batch_ys = train_y[bat_i, :]\n",
    "        sess.run(train_step, feed_dict={xs: batch_xs, ys: batch_ys})\n",
    "        if j % 1000 == 0:\n",
    "            c = compute_accuracy(input_x, input_y, prediction_list[fr_index])\n",
    "            print(c)\n",
    "        if c > 0.95:\n",
    "            print(c)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.914894\n"
     ]
    }
   ],
   "source": [
    "print(test_accuracy(train_x_std2, train_by_frame[1], 25, prediction_list))\n",
    "print(test_accuracy(test_x_std2, test_by_frame[1], 25, prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9148936170212766"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-(4/47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
